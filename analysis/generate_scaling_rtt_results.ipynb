{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "from edgedroid.models.sampling import *\n",
    "from edgedroid.models.timings import *\n",
    "\n",
    "rtts = np.linspace(0, 5, 11)[1:]\n",
    "\n",
    "runs_per_model = 60\n",
    "task_steps = 120\n",
    "\n",
    "timing_models: Dict[str, Callable[[], ExecutionTimeModel]] = {\n",
    "    # \"empirical-low\": lambda: EmpiricalExecutionTimeModel.from_default_data(neuroticism=0.0),\n",
    "    # \"empirical-high\": lambda: EmpiricalExecutionTimeModel.from_default_data(neuroticism=1.0),\n",
    "    # \"theoretical-low\": lambda: TheoreticalExecutionTimeModel.from_default_data(neuroticism=0.0),\n",
    "    # \"theoretical-high\": lambda: TheoreticalExecutionTimeModel.from_default_data(neuroticism=1.0),\n",
    "    # \"constant\": lambda: ConstantExecutionTimeModel.from_default_data(),\n",
    "    # \"naive\": lambda: NaiveExecutionTimeModel.from_default_data(),\n",
    "    # \"fitted-naive\": lambda: FittedNaiveExecutionTimeModel.from_default_data(),\n",
    "    \"rolling-ttf-high\": lambda: ExpKernelRollingTTFETModel(neuroticism=1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "      run_id       ttf  exec_time  neuroticism\n0     134146  0.597441   3.654797        0.375\n1     134146  0.553513   4.438645        0.375\n2     134146  0.561716   2.943222        0.375\n3     134146  0.586512   5.405761        0.375\n4     134146  0.558940   5.225161        0.375\n...      ...       ...        ...          ...\n6755  137353  0.557074   6.439071        0.625\n6756  137353  0.534339   4.680858        0.625\n6757  137353  0.560288   3.467878        0.625\n6758  137353  0.579000   2.325759        0.625\n6759  137353  0.536671   4.615283        0.625\n\n[6760 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>run_id</th>\n      <th>ttf</th>\n      <th>exec_time</th>\n      <th>neuroticism</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>134146</td>\n      <td>0.597441</td>\n      <td>3.654797</td>\n      <td>0.375</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>134146</td>\n      <td>0.553513</td>\n      <td>4.438645</td>\n      <td>0.375</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>134146</td>\n      <td>0.561716</td>\n      <td>2.943222</td>\n      <td>0.375</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>134146</td>\n      <td>0.586512</td>\n      <td>5.405761</td>\n      <td>0.375</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>134146</td>\n      <td>0.558940</td>\n      <td>5.225161</td>\n      <td>0.375</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6755</th>\n      <td>137353</td>\n      <td>0.557074</td>\n      <td>6.439071</td>\n      <td>0.625</td>\n    </tr>\n    <tr>\n      <th>6756</th>\n      <td>137353</td>\n      <td>0.534339</td>\n      <td>4.680858</td>\n      <td>0.625</td>\n    </tr>\n    <tr>\n      <th>6757</th>\n      <td>137353</td>\n      <td>0.560288</td>\n      <td>3.467878</td>\n      <td>0.625</td>\n    </tr>\n    <tr>\n      <th>6758</th>\n      <td>137353</td>\n      <td>0.579000</td>\n      <td>2.325759</td>\n      <td>0.625</td>\n    </tr>\n    <tr>\n      <th>6759</th>\n      <td>137353</td>\n      <td>0.536671</td>\n      <td>4.615283</td>\n      <td>0.625</td>\n    </tr>\n  </tbody>\n</table>\n<p>6760 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import edgedroid.data as e_data\n",
    "\n",
    "data, *_ = e_data.load_default_exec_time_data()\n",
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "25%    3.9\n50%    5.2\n75%    7.0\nName: exec_time, dtype: float64"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exec_time_qs = np.round(data[\"exec_time\"].describe(percentiles=[0.25, 0.5, 0.75])[[\"25%\", \"50%\", \"75%\"]], decimals=1)\n",
    "exec_time_qs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "['greedy',\n 'ideal',\n 'adaptive-power-rolling-ttf',\n 'adaptive-power-rolling-ttf-low',\n 'adaptive-power-rolling-ttf-high',\n 'adaptive-power-fitted-rolling-ttf-exgaussian',\n 'adaptive-power-fitted-rolling-ttf-exgaussian-low',\n 'adaptive-power-fitted-rolling-ttf-exgaussian-high',\n 'adaptive-power-fitted-naive-exgaussian']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from edgedroid.models.sampling.adaptive import _aperiodic_instant_iterator\n",
    "from typing import NamedTuple\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "power_mw = {\n",
    "    # \"comm\": 0.045,\n",
    "    \"comm\": 0.045,\n",
    "    \"idle\": 0.015\n",
    "}  # Watts\n",
    "\n",
    "class SamplingResult(NamedTuple):\n",
    "    duration: float\n",
    "    wait_time: float\n",
    "    ttf: float\n",
    "    num_samples: int\n",
    "\n",
    "\n",
    "class ExpSampling(BaseFrameSamplingModel, abc.ABC):\n",
    "    @abc.abstractmethod\n",
    "    def constant_rtt_sampling(self, rtt: float, proc_time: float, prev_ttf: float,\n",
    "                              target_exec_time: float) -> SamplingResult:\n",
    "        pass\n",
    "\n",
    "\n",
    "class GreedySampling(ZeroWaitFrameSamplingModel, ExpSampling):\n",
    "    def constant_rtt_sampling(self, rtt: float, proc_time: float, prev_ttf: float,\n",
    "                              target_exec_time: float) -> SamplingResult:\n",
    "        num_samples = 1\n",
    "        instant = 0.0\n",
    "\n",
    "        while instant <= target_exec_time:\n",
    "            instant += rtt\n",
    "            num_samples += 1\n",
    "\n",
    "        self.update_timings([rtt - proc_time] * num_samples, [proc_time] * num_samples)\n",
    "        duration = instant + rtt\n",
    "        return SamplingResult(duration=duration, wait_time=instant - target_exec_time, ttf=duration - target_exec_time,\n",
    "                              num_samples=num_samples)\n",
    "\n",
    "\n",
    "class IdealSampling(IdealFrameSamplingModel, ExpSampling):\n",
    "    def constant_rtt_sampling(self, rtt: float, proc_time: float, prev_ttf: float,\n",
    "                              target_exec_time: float) -> SamplingResult:\n",
    "        self.update_timings([rtt - proc_time], [proc_time])\n",
    "        return SamplingResult(duration=target_exec_time + rtt, wait_time=0.0, ttf=rtt, num_samples=1)\n",
    "\n",
    "\n",
    "class PeriodicSampling(RegularFrameSamplingModel, ExpSampling):\n",
    "    def constant_rtt_sampling(self, rtt: float, proc_time: float, prev_ttf: float,\n",
    "                              target_exec_time: float) -> SamplingResult:\n",
    "        num_samples = 1\n",
    "        instant = self._interval\n",
    "\n",
    "        interval = max(self._interval, rtt)\n",
    "\n",
    "        while instant <= target_exec_time:\n",
    "            instant += interval\n",
    "            num_samples += 1\n",
    "\n",
    "        self.update_timings([rtt - proc_time] * num_samples, [proc_time] * num_samples)\n",
    "        duration = instant + rtt\n",
    "        return SamplingResult(duration=duration, wait_time=instant - target_exec_time, ttf=duration - target_exec_time,\n",
    "                              num_samples=num_samples)\n",
    "\n",
    "\n",
    "class HoldSampling(HoldFrameSamplingModel, ExpSampling):\n",
    "    def constant_rtt_sampling(self, rtt: float, proc_time: float, prev_ttf: float,\n",
    "                              target_exec_time: float) -> SamplingResult:\n",
    "        num_samples = 1\n",
    "        instant = self._hold_time\n",
    "\n",
    "        while instant <= target_exec_time:\n",
    "            instant += rtt\n",
    "            num_samples += 1\n",
    "\n",
    "        self.update_timings([rtt - proc_time] * num_samples, [proc_time] * num_samples)\n",
    "        duration = instant + rtt\n",
    "        return SamplingResult(duration=duration, wait_time=instant - target_exec_time, ttf=duration - target_exec_time,\n",
    "                              num_samples=num_samples)\n",
    "\n",
    "\n",
    "class AdaptiveSamplingMixin(BaseAperiodicFrameSamplingModel, ExpSampling, abc.ABC):\n",
    "    def constant_rtt_sampling(self, rtt: float, proc_time: float, prev_ttf: float,\n",
    "                              target_exec_time: float) -> SamplingResult:\n",
    "        self._timing_model.advance(prev_ttf)\n",
    "        alpha = self.get_alpha()\n",
    "        beta = self.get_beta()\n",
    "\n",
    "        instant_iter = _aperiodic_instant_iterator(\n",
    "            mu=self._timing_model.get_expected_execution_time(),\n",
    "            alpha=alpha,\n",
    "            beta=beta,\n",
    "        )\n",
    "        # first instant doesn't depend on RTT\n",
    "        instant = next(instant_iter)\n",
    "        num_samples = 1\n",
    "\n",
    "        while instant <= target_exec_time:\n",
    "            instant = max(next(instant_iter), instant + rtt)\n",
    "            num_samples += 1\n",
    "\n",
    "        self.update_timings([rtt - proc_time] * num_samples, [proc_time] * num_samples)\n",
    "        duration = instant + rtt\n",
    "        return SamplingResult(duration=duration, wait_time=instant - target_exec_time, ttf=duration - target_exec_time,\n",
    "                              num_samples=num_samples)\n",
    "\n",
    "\n",
    "class AdaptiveSampling(AperiodicFrameSamplingModel, AdaptiveSamplingMixin):\n",
    "    pass\n",
    "\n",
    "\n",
    "class AdaptivePowerSampling(AperiodicPowerFrameSamplingModel, AdaptiveSamplingMixin):\n",
    "    pass\n",
    "\n",
    "\n",
    "sampling_schemes: Dict[str, Callable[[], ExpSampling]] = {\n",
    "    \"greedy\": lambda: GreedySampling.from_default_data(),\n",
    "    \"ideal\" : lambda: IdealSampling.from_default_data(),\n",
    "}\n",
    "\n",
    "sampling_schemes.update({\n",
    "    # \"adaptive-empirical\": lambda : AdaptiveSampling.from_default_data(EmpiricalExecutionTimeModel.from_default_data(neuroticism=None)),\n",
    "    # \"adaptive-empirical-low\": lambda : AdaptiveSampling.from_default_data(EmpiricalExecutionTimeModel.from_default_data(neuroticism=0.0)),\n",
    "    # \"adaptive-empirical-high\": lambda : AdaptiveSampling.from_default_data(EmpiricalExecutionTimeModel.from_default_data(neuroticism=1.0)),\n",
    "    # \"adaptive-theoretical-exgaussian\": lambda : AdaptiveSampling.from_default_data(\n",
    "    #     TheoreticalExecutionTimeModel.from_default_data(neuroticism=None, distribution=stats.exponnorm)\n",
    "    # ),\n",
    "    # \"adaptive-theoretical-rayleigh\": lambda : AdaptiveSampling.from_default_data(\n",
    "    #     TheoreticalExecutionTimeModel.from_default_data(neuroticism=None, distribution=stats.rayleigh)\n",
    "    # ),\n",
    "    # \"adaptive-theoretical-exgaussian-low\": lambda : AdaptiveSampling.from_default_data(\n",
    "    #     TheoreticalExecutionTimeModel.from_default_data(neuroticism=0.0, distribution=stats.exponnorm)\n",
    "    # ),\n",
    "    # \"adaptive-theoretical-rayleigh-low\": lambda : AdaptiveSampling.from_default_data(\n",
    "    #     TheoreticalExecutionTimeModel.from_default_data(neuroticism=0.0, distribution=stats.rayleigh)\n",
    "    # ),\n",
    "    # \"adaptive-theoretical-exgaussian-high\": lambda : AdaptiveSampling.from_default_data(\n",
    "    #     TheoreticalExecutionTimeModel.from_default_data(neuroticism=1.0, distribution=stats.exponnorm)\n",
    "    # ),\n",
    "    # \"adaptive-theoretical-rayleigh-high\": lambda : AdaptiveSampling.from_default_data(\n",
    "    #     TheoreticalExecutionTimeModel.from_default_data(neuroticism=1.0, distribution=stats.rayleigh)\n",
    "    # ),\n",
    "    # \"adaptive-fitted-naive-exgaussian\": lambda : AdaptiveSampling.from_default_data(FittedNaiveExecutionTimeModel.from_default_data(dist=stats.exponnorm)),\n",
    "    # \"adaptive-fitted-naive-rayleigh\": lambda : AdaptiveSampling.from_default_data(FittedNaiveExecutionTimeModel.from_default_data(dist=stats.rayleigh))\n",
    "})\n",
    "\n",
    "# sampling_schemes.update({\n",
    "#     f\"adaptive-constant-Q{i + 1}-{t:0.1f}s\":\n",
    "#         lambda : AdaptiveSampling.from_default_data(ConstantExecutionTimeModel(float(t))) for i, t in enumerate(exec_time_qs)\n",
    "# })\n",
    "\n",
    "# sampling_schemes.update({\n",
    "#     \"adaptive-power-empirical\"                  : lambda: AdaptivePowerSampling.from_default_data(\n",
    "#         EmpiricalExecutionTimeModel.from_default_data(neuroticism=None), comm_power_w=power_mw[\"comm\"], idle_power_w=power_mw[\"idle\"]),\n",
    "#     \"adaptive-power-empirical-low\"              : lambda: AdaptivePowerSampling.from_default_data(\n",
    "#         EmpiricalExecutionTimeModel.from_default_data(neuroticism=0.0), comm_power_w=power_mw[\"comm\"], idle_power_w=power_mw[\"idle\"]),\n",
    "#     \"adaptive-power-empirical-high\"             : lambda: AdaptivePowerSampling.from_default_data(\n",
    "#         EmpiricalExecutionTimeModel.from_default_data(neuroticism=1.0), comm_power_w=power_mw[\"comm\"], idle_power_w=power_mw[\"idle\"]),\n",
    "#     \"adaptive-power-theoretical-exgaussian\"     : lambda: AdaptivePowerSampling.from_default_data(\n",
    "#         TheoreticalExecutionTimeModel.from_default_data(neuroticism=None, distribution=stats.exponnorm), comm_power_w=power_mw[\"comm\"], idle_power_w=power_mw[\"idle\"]\n",
    "#     ),\n",
    "#     # \"adaptive-power-theoretical-rayleigh\": lambda : AdaptivePowerSampling.from_default_data(\n",
    "#     #     TheoreticalExecutionTimeModel.from_default_data(neuroticism=None, distribution=stats.rayleigh)\n",
    "#     # ),\n",
    "#     \"adaptive-power-theoretical-exgaussian-low\" : lambda: AdaptivePowerSampling.from_default_data(\n",
    "#         TheoreticalExecutionTimeModel.from_default_data(neuroticism=0.0, distribution=stats.exponnorm), comm_power_w=power_mw[\"comm\"], idle_power_w=power_mw[\"idle\"]\n",
    "#     ),\n",
    "#     # \"adaptive-power-theoretical-rayleigh-low\": lambda : AdaptivePowerSampling.from_default_data(\n",
    "#     #     TheoreticalExecutionTimeModel.from_default_data(neuroticism=0.0, distribution=stats.rayleigh)\n",
    "#     # ),\n",
    "#     \"adaptive-power-theoretical-exgaussian-high\": lambda: AdaptivePowerSampling.from_default_data(\n",
    "#         TheoreticalExecutionTimeModel.from_default_data(neuroticism=1.0, distribution=stats.exponnorm), comm_power_w=power_mw[\"comm\"], idle_power_w=power_mw[\"idle\"]\n",
    "#     ),\n",
    "#     # \"adaptive-power-theoretical-rayleigh-high\": lambda : AdaptivePowerSampling.from_default_data(\n",
    "#     #     TheoreticalExecutionTimeModel.from_default_data(neuroticism=1.0, distribution=stats.rayleigh)\n",
    "#     # ),\n",
    "#     \"adaptive-power-fitted-naive-exgaussian\"    : lambda: AdaptivePowerSampling.from_default_data(\n",
    "#         FittedNaiveExecutionTimeModel.from_default_data(dist=stats.exponnorm), comm_power_w=power_mw[\"comm\"], idle_power_w=power_mw[\"idle\"]\n",
    "#     ),\n",
    "#     # \"adaptive-power-fitted-naive-rayleigh\": lambda : AdaptivePowerSampling.from_default_data(FittedNaiveExecutionTimeModel.from_default_data(dist=stats.rayleigh))\n",
    "# })\n",
    "\n",
    "sampling_schemes.update({\n",
    "    \"adaptive-power-rolling-ttf\"                  : lambda: AdaptivePowerSampling.from_default_data(\n",
    "        ExpKernelRollingTTFETModel(neuroticism=None), comm_power_w=power_mw[\"comm\"], idle_power_w=power_mw[\"idle\"]),\n",
    "    \"adaptive-power-rolling-ttf-low\"              : lambda: AdaptivePowerSampling.from_default_data(\n",
    "        ExpKernelRollingTTFETModel(neuroticism=0.0), comm_power_w=power_mw[\"comm\"], idle_power_w=power_mw[\"idle\"]),\n",
    "    \"adaptive-power-rolling-ttf-high\"              : lambda: AdaptivePowerSampling.from_default_data(\n",
    "        ExpKernelRollingTTFETModel(neuroticism=1.0), comm_power_w=power_mw[\"comm\"], idle_power_w=power_mw[\"idle\"]),\n",
    "    \"adaptive-power-fitted-rolling-ttf-exgaussian\"     : lambda: AdaptivePowerSampling.from_default_data(\n",
    "        DistExpKernelRollingTTFETModel(neuroticism=None, dist=stats.exponnorm), comm_power_w=power_mw[\"comm\"], idle_power_w=power_mw[\"idle\"]\n",
    "    ),\n",
    "    \"adaptive-power-fitted-rolling-ttf-exgaussian-low\"     : lambda: AdaptivePowerSampling.from_default_data(\n",
    "        DistExpKernelRollingTTFETModel(neuroticism=0.0, dist=stats.exponnorm), comm_power_w=power_mw[\"comm\"], idle_power_w=power_mw[\"idle\"]\n",
    "    ),\n",
    "    \"adaptive-power-fitted-rolling-ttf-exgaussian-high\"     : lambda: AdaptivePowerSampling.from_default_data(\n",
    "        DistExpKernelRollingTTFETModel(neuroticism=1.0, dist=stats.exponnorm), comm_power_w=power_mw[\"comm\"], idle_power_w=power_mw[\"idle\"]\n",
    "    ),\n",
    "    \"adaptive-power-fitted-naive-exgaussian\"    : lambda: AdaptivePowerSampling.from_default_data(\n",
    "        FittedNaiveExecutionTimeModel(dist=stats.exponnorm), comm_power_w=power_mw[\"comm\"], idle_power_w=power_mw[\"idle\"]\n",
    "    ),\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "# sampling_schemes.update({\n",
    "#     f\"adaptive-power-constant-Q{i + 1}-{t:0.1f}s\":\n",
    "#         lambda : AdaptivePowerSampling.from_default_data(ConstantExecutionTimeModel(float(t))) for i, t in enumerate(exec_time_qs)\n",
    "# })\n",
    "\n",
    "# sampling_schemes.update({\n",
    "#     f\"periodic-{t:0.1f}s\": lambda : PeriodicSampling.from_default_data(sampling_interval_seconds=float(t)) for t in (0.125, 0.25, 0.5, 1)\n",
    "# })\n",
    "# sampling_schemes.update({\n",
    "#     f\"hold-{t:0.1f}s\": lambda : HoldSampling.from_default_data(hold_time_seconds=float(t)) for t in (3, 5, 7)\n",
    "# })\n",
    "\n",
    "list(sampling_schemes.keys())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "proc_time = 0.3  # 300 ms\n",
    "# warmup_steps = 20\n",
    "\n",
    "def run_combination(timing: str, sampling: str, rtt: float, repetition: int) -> pd.DataFrame:\n",
    "    timing_model = timing_models[timing]()\n",
    "    sampling_model = sampling_schemes[sampling]()\n",
    "    prev_ttf = rtt\n",
    "    cumulative_duration = 0.0\n",
    "    cumulative_samples = 0\n",
    "\n",
    "    # for power calculations:\n",
    "    comm_time_per_sample = rtt - proc_time\n",
    "    cumulative_energy = 0.0\n",
    "\n",
    "    rows = deque()\n",
    "    sampling_model.update_timings([comm_time_per_sample], [proc_time])\n",
    "\n",
    "    for step in range(1, task_steps + 1):\n",
    "        exec_time = timing_model.advance(prev_ttf).get_execution_time()\n",
    "        duration, wait_time, ttf, num_samples = sampling_model.constant_rtt_sampling(rtt=rtt, proc_time=proc_time, prev_ttf=prev_ttf, target_exec_time=exec_time)\n",
    "\n",
    "        cumulative_duration += duration\n",
    "        cumulative_samples += num_samples\n",
    "\n",
    "        # calculate power\n",
    "        comm_time = comm_time_per_sample * num_samples\n",
    "        idle_time = duration - comm_time\n",
    "        comm_energy = comm_time * power_mw[\"comm\"]\n",
    "        idle_energy = idle_time * power_mw[\"idle\"]\n",
    "\n",
    "        total_energy = comm_energy + idle_energy\n",
    "        cumulative_energy += total_energy\n",
    "\n",
    "        rows.append(\n",
    "            {\n",
    "                \"timing_model\"       : timing,\n",
    "                \"sampling_scheme\"    : sampling,\n",
    "                \"rtt\"                : rtt,\n",
    "                \"step\"               : step,\n",
    "                \"previous_ttf\"       : prev_ttf,\n",
    "                \"execution_time\"     : exec_time,\n",
    "                \"step_duration\"      : duration,\n",
    "                \"ttf\"                : ttf,\n",
    "                \"wait_time\"          : wait_time,\n",
    "                \"samples\"            : num_samples,\n",
    "                \"cumulative_duration\": cumulative_duration,\n",
    "                \"cumulative_samples\" : cumulative_samples,\n",
    "                \"repetition\"         : repetition,\n",
    "                \"energy\"             : total_energy,\n",
    "                \"cumulative_energy\"  : cumulative_energy,\n",
    "                \"comm_time\"          : comm_time,\n",
    "                \"idle_time\"          : idle_time,\n",
    "                \"comm_energy\"        : comm_energy,\n",
    "                \"idle_energy\"        : idle_energy,\n",
    "            }\n",
    "        )\n",
    "        prev_ttf = ttf\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "Running timing model/sampling scheme combinations...:   0%|          0/5400 [Time: 00:00]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c3ac1c8ba59547628f22b6285625a1e4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "       timing_model                         sampling_scheme  rtt  step  \\\n0               NaN                                  greedy  1.5     1   \n1               NaN                                  greedy  1.5     2   \n2               NaN                                  greedy  1.5     3   \n3               NaN                                  greedy  1.5     4   \n4               NaN                                  greedy  1.5     5   \n...             ...                                     ...  ...   ...   \n647995          NaN  adaptive-power-fitted-naive-exgaussian  2.5   116   \n647996          NaN  adaptive-power-fitted-naive-exgaussian  2.5   117   \n647997          NaN  adaptive-power-fitted-naive-exgaussian  2.5   118   \n647998          NaN  adaptive-power-fitted-naive-exgaussian  2.5   119   \n647999          NaN  adaptive-power-fitted-naive-exgaussian  2.5   120   \n\n        previous_ttf  execution_time  step_duration       ttf  wait_time  \\\n0           1.500000        4.301479       6.000000  1.698521   0.198521   \n1           1.698521        4.489990       6.000000  1.510010   0.010010   \n2           1.510010        5.434791       7.500000  2.065209   0.565209   \n3           2.065209        6.279299       9.000000  2.720701   1.220701   \n4           2.720701        4.345439       6.000000  1.654561   0.154561   \n...              ...             ...            ...       ...        ...   \n647995      7.316475        5.157192      10.050428  4.893236   2.393236   \n647996      4.893236        7.899450      14.485558  6.586108   4.086108   \n647997      6.586108       11.103513      14.485558  3.382045   0.882045   \n647998      3.382045        5.511971      10.050428  4.538457   2.038457   \n647999      4.538457        4.000099      10.050428  6.050330   3.550330   \n\n        samples  cumulative_duration  cumulative_samples  repetition  \\\n0             4             6.000000                   4           6   \n1             4            12.000000                   8           6   \n2             5            19.500000                  13           6   \n3             6            28.500000                  19           6   \n4             4            34.500000                  23           6   \n...         ...                  ...                 ...         ...   \n647995        1          1384.952239                 169          20   \n647996        2          1399.437797                 171          20   \n647997        2          1413.923355                 173          20   \n647998        1          1423.973784                 174          20   \n647999        1          1434.024212                 175          20   \n\n          energy  cumulative_energy  comm_time  idle_time  comm_energy  \\\n0       0.234000           0.234000        4.8   1.200000        0.216   \n1       0.234000           0.468000        4.8   1.200000        0.216   \n2       0.292500           0.760500        6.0   1.500000        0.270   \n3       0.351000           1.111500        7.2   1.800000        0.324   \n4       0.234000           1.345500        4.8   1.200000        0.216   \n...          ...                ...        ...        ...          ...   \n647995  0.216756          31.928284        2.2   7.850428        0.099   \n647996  0.349283          32.277567        4.4  10.085558        0.198   \n647997  0.349283          32.626850        4.4  10.085558        0.198   \n647998  0.216756          32.843607        2.2   7.850428        0.099   \n647999  0.216756          33.060363        2.2   7.850428        0.099   \n\n        idle_energy  \n0          0.018000  \n1          0.018000  \n2          0.022500  \n3          0.027000  \n4          0.018000  \n...             ...  \n647995     0.117756  \n647996     0.151283  \n647997     0.151283  \n647998     0.117756  \n647999     0.117756  \n\n[648000 rows x 19 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timing_model</th>\n      <th>sampling_scheme</th>\n      <th>rtt</th>\n      <th>step</th>\n      <th>previous_ttf</th>\n      <th>execution_time</th>\n      <th>step_duration</th>\n      <th>ttf</th>\n      <th>wait_time</th>\n      <th>samples</th>\n      <th>cumulative_duration</th>\n      <th>cumulative_samples</th>\n      <th>repetition</th>\n      <th>energy</th>\n      <th>cumulative_energy</th>\n      <th>comm_time</th>\n      <th>idle_time</th>\n      <th>comm_energy</th>\n      <th>idle_energy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>greedy</td>\n      <td>1.5</td>\n      <td>1</td>\n      <td>1.500000</td>\n      <td>4.301479</td>\n      <td>6.000000</td>\n      <td>1.698521</td>\n      <td>0.198521</td>\n      <td>4</td>\n      <td>6.000000</td>\n      <td>4</td>\n      <td>6</td>\n      <td>0.234000</td>\n      <td>0.234000</td>\n      <td>4.8</td>\n      <td>1.200000</td>\n      <td>0.216</td>\n      <td>0.018000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>greedy</td>\n      <td>1.5</td>\n      <td>2</td>\n      <td>1.698521</td>\n      <td>4.489990</td>\n      <td>6.000000</td>\n      <td>1.510010</td>\n      <td>0.010010</td>\n      <td>4</td>\n      <td>12.000000</td>\n      <td>8</td>\n      <td>6</td>\n      <td>0.234000</td>\n      <td>0.468000</td>\n      <td>4.8</td>\n      <td>1.200000</td>\n      <td>0.216</td>\n      <td>0.018000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>greedy</td>\n      <td>1.5</td>\n      <td>3</td>\n      <td>1.510010</td>\n      <td>5.434791</td>\n      <td>7.500000</td>\n      <td>2.065209</td>\n      <td>0.565209</td>\n      <td>5</td>\n      <td>19.500000</td>\n      <td>13</td>\n      <td>6</td>\n      <td>0.292500</td>\n      <td>0.760500</td>\n      <td>6.0</td>\n      <td>1.500000</td>\n      <td>0.270</td>\n      <td>0.022500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>greedy</td>\n      <td>1.5</td>\n      <td>4</td>\n      <td>2.065209</td>\n      <td>6.279299</td>\n      <td>9.000000</td>\n      <td>2.720701</td>\n      <td>1.220701</td>\n      <td>6</td>\n      <td>28.500000</td>\n      <td>19</td>\n      <td>6</td>\n      <td>0.351000</td>\n      <td>1.111500</td>\n      <td>7.2</td>\n      <td>1.800000</td>\n      <td>0.324</td>\n      <td>0.027000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>greedy</td>\n      <td>1.5</td>\n      <td>5</td>\n      <td>2.720701</td>\n      <td>4.345439</td>\n      <td>6.000000</td>\n      <td>1.654561</td>\n      <td>0.154561</td>\n      <td>4</td>\n      <td>34.500000</td>\n      <td>23</td>\n      <td>6</td>\n      <td>0.234000</td>\n      <td>1.345500</td>\n      <td>4.8</td>\n      <td>1.200000</td>\n      <td>0.216</td>\n      <td>0.018000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>647995</th>\n      <td>NaN</td>\n      <td>adaptive-power-fitted-naive-exgaussian</td>\n      <td>2.5</td>\n      <td>116</td>\n      <td>7.316475</td>\n      <td>5.157192</td>\n      <td>10.050428</td>\n      <td>4.893236</td>\n      <td>2.393236</td>\n      <td>1</td>\n      <td>1384.952239</td>\n      <td>169</td>\n      <td>20</td>\n      <td>0.216756</td>\n      <td>31.928284</td>\n      <td>2.2</td>\n      <td>7.850428</td>\n      <td>0.099</td>\n      <td>0.117756</td>\n    </tr>\n    <tr>\n      <th>647996</th>\n      <td>NaN</td>\n      <td>adaptive-power-fitted-naive-exgaussian</td>\n      <td>2.5</td>\n      <td>117</td>\n      <td>4.893236</td>\n      <td>7.899450</td>\n      <td>14.485558</td>\n      <td>6.586108</td>\n      <td>4.086108</td>\n      <td>2</td>\n      <td>1399.437797</td>\n      <td>171</td>\n      <td>20</td>\n      <td>0.349283</td>\n      <td>32.277567</td>\n      <td>4.4</td>\n      <td>10.085558</td>\n      <td>0.198</td>\n      <td>0.151283</td>\n    </tr>\n    <tr>\n      <th>647997</th>\n      <td>NaN</td>\n      <td>adaptive-power-fitted-naive-exgaussian</td>\n      <td>2.5</td>\n      <td>118</td>\n      <td>6.586108</td>\n      <td>11.103513</td>\n      <td>14.485558</td>\n      <td>3.382045</td>\n      <td>0.882045</td>\n      <td>2</td>\n      <td>1413.923355</td>\n      <td>173</td>\n      <td>20</td>\n      <td>0.349283</td>\n      <td>32.626850</td>\n      <td>4.4</td>\n      <td>10.085558</td>\n      <td>0.198</td>\n      <td>0.151283</td>\n    </tr>\n    <tr>\n      <th>647998</th>\n      <td>NaN</td>\n      <td>adaptive-power-fitted-naive-exgaussian</td>\n      <td>2.5</td>\n      <td>119</td>\n      <td>3.382045</td>\n      <td>5.511971</td>\n      <td>10.050428</td>\n      <td>4.538457</td>\n      <td>2.038457</td>\n      <td>1</td>\n      <td>1423.973784</td>\n      <td>174</td>\n      <td>20</td>\n      <td>0.216756</td>\n      <td>32.843607</td>\n      <td>2.2</td>\n      <td>7.850428</td>\n      <td>0.099</td>\n      <td>0.117756</td>\n    </tr>\n    <tr>\n      <th>647999</th>\n      <td>NaN</td>\n      <td>adaptive-power-fitted-naive-exgaussian</td>\n      <td>2.5</td>\n      <td>120</td>\n      <td>4.538457</td>\n      <td>4.000099</td>\n      <td>10.050428</td>\n      <td>6.050330</td>\n      <td>3.550330</td>\n      <td>1</td>\n      <td>1434.024212</td>\n      <td>175</td>\n      <td>20</td>\n      <td>0.216756</td>\n      <td>33.060363</td>\n      <td>2.2</td>\n      <td>7.850428</td>\n      <td>0.099</td>\n      <td>0.117756</td>\n    </tr>\n  </tbody>\n</table>\n<p>648000 rows × 19 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import multiprocess as mp\n",
    "import shutil\n",
    "\n",
    "result_path = \"./sampling_scaling_rtt.gzip\"\n",
    "combs = set(itertools.product(timing_models.keys(), sampling_schemes.keys(), rtts, range(1, runs_per_model + 1)))\n",
    "\n",
    "# only calculate missing results\n",
    "results = deque()\n",
    "\n",
    "try:\n",
    "    old_results = pd.read_parquet(result_path)\n",
    "    existing_combinations = set(\n",
    "        old_results[[\"timing_model\", \"sampling_scheme\", \"rtt\", \"repetition\"]].itertuples(index=False))\n",
    "    shutil.rmtree(result_path)\n",
    "    results.append(old_results)\n",
    "except FileNotFoundError:\n",
    "    existing_combinations = set()\n",
    "\n",
    "combs.difference_update(existing_combinations)\n",
    "if len(combs) == 0:\n",
    "    print(\"No missing combinations.\")\n",
    "else:\n",
    "    # noinspection PyUnresolvedReferences\n",
    "    with tqdm(\n",
    "        total=len(combs),\n",
    "        desc=\"Running timing model/sampling scheme combinations...\",\n",
    "        bar_format=\"{l_bar}{bar}{n_fmt}/{total_fmt} [Time: {elapsed}]\"\n",
    "    ) as bar, mp.Pool(\n",
    "        processes=os.cpu_count() - 1,\n",
    "        maxtasksperchild=10\n",
    "    ) as pool:\n",
    "\n",
    "        def _callback(result: pd.DataFrame):\n",
    "            bar.update()\n",
    "            results.append(result)\n",
    "\n",
    "        for c in combs:\n",
    "            pool.apply_async(run_combination, args=c, callback=_callback)\n",
    "\n",
    "        pool.close()\n",
    "        pool.join()  # wait for workers\n",
    "\n",
    "results = pd.concat(results, ignore_index=True)\n",
    "results[\"timing_model\"] = results[\"timing_model\"].astype()\n",
    "results[\"sampling_scheme\"] = results[\"sampling_scheme\"].astype(\n",
    "    pd.CategoricalDtype(sampling_schemes.keys(), ordered=False)\n",
    ")\n",
    "results.to_parquet(result_path, partition_cols=[\"timing_model\", \"sampling_scheme\"], compression=\"gzip\")\n",
    "results"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
