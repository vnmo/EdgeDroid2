{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "from edgedroid.models.sampling import *\n",
    "from edgedroid.models.timings import *\n",
    "\n",
    "rtts = np.linspace(0, 5, 10)[1:]\n",
    "\n",
    "runs_per_model = 15\n",
    "task_steps = 100\n",
    "\n",
    "timing_models: Dict[str, Callable[[], ExecutionTimeModel]] = {\n",
    "    \"empirical-low\": lambda: EmpiricalExecutionTimeModel.from_default_data(neuroticism=0.0),\n",
    "    \"empirical-high\": lambda: EmpiricalExecutionTimeModel.from_default_data(neuroticism=1.0),\n",
    "    \"theoretical-low\": lambda: TheoreticalExecutionTimeModel.from_default_data(neuroticism=0.0),\n",
    "    \"theoretical-high\": lambda: TheoreticalExecutionTimeModel.from_default_data(neuroticism=1.0),\n",
    "    # \"constant\": lambda: ConstantExecutionTimeModel.from_default_data(),\n",
    "    # \"naive\": lambda: NaiveExecutionTimeModel.from_default_data(),\n",
    "    # \"fitted-naive\": lambda: FittedNaiveExecutionTimeModel.from_default_data(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "      run_id       ttf  exec_time  neuroticism\n0     134146  0.597441   3.654797        0.375\n1     134146  0.553513   4.438645        0.375\n2     134146  0.561716   2.943222        0.375\n3     134146  0.586512   5.405761        0.375\n4     134146  0.558940   5.225161        0.375\n...      ...       ...        ...          ...\n6755  137353  0.557074   6.439071        0.625\n6756  137353  0.534339   4.680858        0.625\n6757  137353  0.560288   3.467878        0.625\n6758  137353  0.579000   2.325759        0.625\n6759  137353  0.536671   4.615283        0.625\n\n[6760 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>run_id</th>\n      <th>ttf</th>\n      <th>exec_time</th>\n      <th>neuroticism</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>134146</td>\n      <td>0.597441</td>\n      <td>3.654797</td>\n      <td>0.375</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>134146</td>\n      <td>0.553513</td>\n      <td>4.438645</td>\n      <td>0.375</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>134146</td>\n      <td>0.561716</td>\n      <td>2.943222</td>\n      <td>0.375</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>134146</td>\n      <td>0.586512</td>\n      <td>5.405761</td>\n      <td>0.375</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>134146</td>\n      <td>0.558940</td>\n      <td>5.225161</td>\n      <td>0.375</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6755</th>\n      <td>137353</td>\n      <td>0.557074</td>\n      <td>6.439071</td>\n      <td>0.625</td>\n    </tr>\n    <tr>\n      <th>6756</th>\n      <td>137353</td>\n      <td>0.534339</td>\n      <td>4.680858</td>\n      <td>0.625</td>\n    </tr>\n    <tr>\n      <th>6757</th>\n      <td>137353</td>\n      <td>0.560288</td>\n      <td>3.467878</td>\n      <td>0.625</td>\n    </tr>\n    <tr>\n      <th>6758</th>\n      <td>137353</td>\n      <td>0.579000</td>\n      <td>2.325759</td>\n      <td>0.625</td>\n    </tr>\n    <tr>\n      <th>6759</th>\n      <td>137353</td>\n      <td>0.536671</td>\n      <td>4.615283</td>\n      <td>0.625</td>\n    </tr>\n  </tbody>\n</table>\n<p>6760 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import edgedroid.data as e_data\n",
    "data, *_ = e_data.load_default_exec_time_data()\n",
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "25%    3.9\n50%    5.2\n75%    7.0\nName: exec_time, dtype: float64"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exec_time_qs = np.round(data[\"exec_time\"].describe(percentiles=[0.25, 0.5, 0.75])[[\"25%\", \"50%\", \"75%\"]], decimals=1)\n",
    "exec_time_qs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "['greedy',\n 'ideal',\n 'adaptive-empirical',\n 'adaptive-empirical-low',\n 'adaptive-empirical-high',\n 'adaptive-theoretical',\n 'adaptive-theoretical-low',\n 'adaptive-theoretical-high',\n 'adaptive-fitted-naive',\n 'adaptive-constant-Q1-3.9s',\n 'adaptive-constant-Q2-5.2s',\n 'adaptive-constant-Q3-7.0s',\n 'adaptive-power-empirical',\n 'adaptive-power-empirical-low',\n 'adaptive-power-empirical-high',\n 'adaptive-power-theoretical',\n 'adaptive-power-theoretical-low',\n 'adaptive-power-theoretical-high',\n 'adaptive-power-fitted-naive',\n 'adaptive-power-constant-Q1-3.9s',\n 'adaptive-power-constant-Q2-5.2s',\n 'adaptive-power-constant-Q3-7.0s',\n 'periodic-1.0s',\n 'periodic-3.0s',\n 'periodic-5.0s',\n 'hold-1.0s',\n 'hold-3.0s',\n 'hold-5.0s']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from edgedroid.models.sampling.adaptive import _aperiodic_instant_iterator\n",
    "from typing import NamedTuple\n",
    "\n",
    "class SamplingResult(NamedTuple):\n",
    "    final_sampling_instant: float\n",
    "    num_samples: int\n",
    "\n",
    "class ExpSampling(BaseFrameSamplingModel, abc.ABC):\n",
    "    @abc.abstractmethod\n",
    "    def constant_rtt_sampling(self, rtt: float, prev_ttf: float, target_exec_time: float) -> SamplingResult:\n",
    "        pass\n",
    "\n",
    "\n",
    "class GreedySampling(ZeroWaitFrameSamplingModel, ExpSampling):\n",
    "    def constant_rtt_sampling(self, rtt: float, prev_ttf: float, target_exec_time: float) -> SamplingResult:\n",
    "        num_samples = 1\n",
    "        instant = 0.0\n",
    "\n",
    "        while instant <= target_exec_time:\n",
    "            instant += rtt\n",
    "            num_samples += 1\n",
    "\n",
    "        return SamplingResult(instant, num_samples)\n",
    "\n",
    "class IdealSampling(IdealFrameSamplingModel, ExpSampling):\n",
    "    def constant_rtt_sampling(self, rtt: float, prev_ttf: float, target_exec_time: float) -> SamplingResult:\n",
    "        return SamplingResult(target_exec_time, 1)\n",
    "\n",
    "class PeriodicSampling(RegularFrameSamplingModel, ExpSampling):\n",
    "    def constant_rtt_sampling(self, rtt: float, prev_ttf: float, target_exec_time: float) -> SamplingResult:\n",
    "        num_samples = 1\n",
    "        instant = self._interval\n",
    "\n",
    "        interval = max(self._interval, rtt)\n",
    "\n",
    "        while instant <= target_exec_time:\n",
    "            instant += interval\n",
    "            num_samples += 1\n",
    "\n",
    "        return SamplingResult(instant, num_samples)\n",
    "\n",
    "class HoldSampling(HoldFrameSamplingModel, ExpSampling):\n",
    "    def constant_rtt_sampling(self, rtt: float, prev_ttf: float, target_exec_time: float) -> SamplingResult:\n",
    "        num_samples = 1\n",
    "        instant = self._hold_time\n",
    "\n",
    "        while instant <= target_exec_time:\n",
    "            instant += rtt\n",
    "            num_samples += 1\n",
    "\n",
    "        return SamplingResult(instant, num_samples)\n",
    "\n",
    "class AdaptiveSamplingMixin(BaseAperiodicFrameSamplingModel, ExpSampling, abc.ABC):\n",
    "    def constant_rtt_sampling(self, rtt: float, prev_ttf: float, target_exec_time: float) -> SamplingResult:\n",
    "        self._timing_model.advance(prev_ttf)\n",
    "        alpha = self.get_alpha()\n",
    "        beta = self.get_beta()\n",
    "\n",
    "        rtts = deque()\n",
    "        prev_instant = 0.0\n",
    "        for instant in _aperiodic_instant_iterator(\n",
    "            mu=self._timing_model.get_expected_execution_time(),\n",
    "            alpha=alpha,\n",
    "            beta=beta,\n",
    "        ):\n",
    "            rtts.append(rtt)\n",
    "            instant = max(instant, prev_instant + rtt)\n",
    "\n",
    "            if instant > target_exec_time:\n",
    "                self.record_rtts(rtts)\n",
    "                return SamplingResult(instant, len(rtts))\n",
    "            else:\n",
    "                prev_instant = instant\n",
    "\n",
    "class AdaptiveSampling(AperiodicFrameSamplingModel, AdaptiveSamplingMixin):\n",
    "    pass\n",
    "\n",
    "class AdaptivePowerSampling(AperiodicPowerFrameSamplingModel, AdaptiveSamplingMixin):\n",
    "    pass\n",
    "\n",
    "sampling_schemes: Dict[str, Callable[[], ExpSampling]] = {\n",
    "    \"greedy\": lambda : GreedySampling.from_default_data(),\n",
    "    \"ideal\": lambda : IdealSampling.from_default_data(),\n",
    "}\n",
    "\n",
    "sampling_schemes.update({\n",
    "    \"adaptive-empirical\": lambda : AdaptiveSampling.from_default_data(EmpiricalExecutionTimeModel.from_default_data(neuroticism=None)),\n",
    "    \"adaptive-empirical-low\": lambda : AdaptiveSampling.from_default_data(EmpiricalExecutionTimeModel.from_default_data(neuroticism=0.0)),\n",
    "    \"adaptive-empirical-high\": lambda : AdaptiveSampling.from_default_data(EmpiricalExecutionTimeModel.from_default_data(neuroticism=1.0)),\n",
    "    \"adaptive-theoretical\": lambda : AdaptiveSampling.from_default_data(TheoreticalExecutionTimeModel.from_default_data(neuroticism=None)),\n",
    "    \"adaptive-theoretical-low\": lambda : AdaptiveSampling.from_default_data(TheoreticalExecutionTimeModel.from_default_data(neuroticism=0.0)),\n",
    "    \"adaptive-theoretical-high\": lambda : AdaptiveSampling.from_default_data(TheoreticalExecutionTimeModel.from_default_data(neuroticism=1.0)),\n",
    "    \"adaptive-fitted-naive\": lambda : AdaptiveSampling.from_default_data(FittedNaiveExecutionTimeModel.from_default_data())\n",
    "})\n",
    "\n",
    "sampling_schemes.update({\n",
    "    f\"adaptive-constant-Q{i + 1}-{t:0.1f}s\":\n",
    "        lambda : AdaptiveSampling.from_default_data(ConstantExecutionTimeModel(float(t))) for i, t in enumerate(exec_time_qs)\n",
    "})\n",
    "\n",
    "sampling_schemes.update({\n",
    "    \"adaptive-power-empirical\": lambda : AdaptivePowerSampling.from_default_data(EmpiricalExecutionTimeModel.from_default_data(neuroticism=None)),\n",
    "    \"adaptive-power-empirical-low\": lambda : AdaptivePowerSampling.from_default_data(EmpiricalExecutionTimeModel.from_default_data(neuroticism=0.0)),\n",
    "    \"adaptive-power-empirical-high\": lambda : AdaptivePowerSampling.from_default_data(EmpiricalExecutionTimeModel.from_default_data(neuroticism=1.0)),\n",
    "    \"adaptive-power-theoretical\": lambda : AdaptivePowerSampling.from_default_data(TheoreticalExecutionTimeModel.from_default_data(neuroticism=None)),\n",
    "    \"adaptive-power-theoretical-low\": lambda : AdaptivePowerSampling.from_default_data(TheoreticalExecutionTimeModel.from_default_data(neuroticism=0.0)),\n",
    "    \"adaptive-power-theoretical-high\": lambda : AdaptivePowerSampling.from_default_data(TheoreticalExecutionTimeModel.from_default_data(neuroticism=1.0)),\n",
    "    \"adaptive-power-fitted-naive\": lambda : AdaptivePowerSampling.from_default_data(FittedNaiveExecutionTimeModel.from_default_data())\n",
    "})\n",
    "\n",
    "sampling_schemes.update({\n",
    "    f\"adaptive-power-constant-Q{i + 1}-{t:0.1f}s\":\n",
    "        lambda : AdaptivePowerSampling.from_default_data(ConstantExecutionTimeModel(float(t))) for i, t in enumerate(exec_time_qs)\n",
    "})\n",
    "\n",
    "sampling_schemes.update({\n",
    "    f\"periodic-{t:0.1f}s\": lambda : PeriodicSampling.from_default_data(sampling_interval_seconds=float(t)) for t in (1, 3, 5)\n",
    "})\n",
    "sampling_schemes.update({\n",
    "    f\"hold-{t:0.1f}s\": lambda : HoldSampling.from_default_data(hold_time_seconds=float(t)) for t in (1, 3, 5)\n",
    "})\n",
    "\n",
    "list(sampling_schemes.keys())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "power_mw = {\n",
    "    \"comm\": 0.045,\n",
    "    \"idle\": 0.015\n",
    "}  # Watts\n",
    "\n",
    "proc_time = 0.3 # 300 ms\n",
    "\n",
    "def run_combination(timing: str, sampling: str, rtt: float, repetition: int) -> pd.DataFrame:\n",
    "    timing_model = timing_models[timing]()\n",
    "    sampling_model = sampling_schemes[sampling]()\n",
    "    prev_ttf = rtt\n",
    "    cumulative_duration = 0.0\n",
    "    cumulative_samples = 0\n",
    "\n",
    "    # for power calculations:\n",
    "    comm_time_per_sample = rtt - proc_time\n",
    "    cumulative_energy = 0.0\n",
    "\n",
    "    rows = deque()\n",
    "\n",
    "    for step in range(1, task_steps + 1):\n",
    "        exec_time = timing_model.advance(prev_ttf).get_execution_time()\n",
    "        final_sample, num_samples = sampling_model.constant_rtt_sampling(rtt, prev_ttf, exec_time)\n",
    "\n",
    "        duration = final_sample + rtt\n",
    "        cumulative_duration += duration\n",
    "        cumulative_samples += num_samples\n",
    "        ttf = duration - exec_time\n",
    "        wait_time = ttf - rtt\n",
    "\n",
    "        # calculate power\n",
    "        total_comm_time = comm_time_per_sample * num_samples\n",
    "        total_idle_time = duration - total_comm_time\n",
    "\n",
    "        total_energy = (total_idle_time * power_mw[\"idle\"]) + (total_comm_time * power_mw[\"comm\"])\n",
    "        cumulative_energy += total_energy\n",
    "\n",
    "        rows.append(\n",
    "            {\n",
    "                \"timing_model\": timing,\n",
    "                \"sampling_scheme\": sampling,\n",
    "                \"rtt\": rtt,\n",
    "                \"step\": step,\n",
    "                \"previous_ttf\": prev_ttf,\n",
    "                \"execution_time\": exec_time,\n",
    "                \"step_duration\": duration,\n",
    "                \"ttf\": ttf,\n",
    "                \"wait_time\": wait_time,\n",
    "                \"samples\": num_samples,\n",
    "                \"cumulative_duration\": cumulative_duration,\n",
    "                \"cumulative_samples\": cumulative_samples,\n",
    "                \"repetition\": repetition,\n",
    "                \"energy\": total_energy,\n",
    "                \"cumulative_energy\": cumulative_energy,\n",
    "            }\n",
    "        )\n",
    "        prev_ttf = ttf\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          0/15120 [Time: 00:00]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f3ee8c82b8e64e44b0236088e453204b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "            timing_model            sampling_scheme       rtt  step  \\\n0         empirical-high  adaptive-constant-Q2-5.2s  2.777778     1   \n1         empirical-high  adaptive-constant-Q2-5.2s  2.777778     2   \n2         empirical-high  adaptive-constant-Q2-5.2s  2.777778     3   \n3         empirical-high  adaptive-constant-Q2-5.2s  2.777778     4   \n4         empirical-high  adaptive-constant-Q2-5.2s  2.777778     5   \n...                  ...                        ...       ...   ...   \n1511995  theoretical-low     adaptive-empirical-low  3.888889    96   \n1511996  theoretical-low     adaptive-empirical-low  3.888889    97   \n1511997  theoretical-low     adaptive-empirical-low  3.888889    98   \n1511998  theoretical-low     adaptive-empirical-low  3.888889    99   \n1511999  theoretical-low     adaptive-empirical-low  3.888889   100   \n\n         previous_ttf  execution_time  step_duration       ttf  wait_time  \\\n0            2.777778        7.071596      11.111111  4.039515   1.261737   \n1            4.039515        8.879713      12.234523  3.354810   0.577032   \n2            3.354810        4.495618       9.832383  5.336765   2.558987   \n3            5.336765        0.533615       7.452374  6.918759   4.140981   \n4            6.918759        8.872578      14.013848  5.141270   2.363493   \n...               ...             ...            ...       ...        ...   \n1511995      6.888578        5.993087      10.922816  4.929729   1.040840   \n1511996      4.929729        7.726390      15.054552  7.328162   3.439273   \n1511997      7.328162        4.544998      10.680071  6.135073   2.246184   \n1511998      6.135073        6.428863      10.680071  4.251207   0.362319   \n1511999      4.251207        6.287216      10.680071  4.392855   0.503966   \n\n         samples  cumulative_duration  cumulative_samples  repetition  \\\n0              3            11.111111                   3          12   \n1              3            23.345634                   6          12   \n2              2            33.178017                   8          12   \n3              1            40.630391                   9          12   \n4              3            54.644239                  12          12   \n...          ...                  ...                 ...         ...   \n1511995        1          1123.539389                 127          13   \n1511996        2          1138.593941                 129          13   \n1511997        1          1149.274012                 130          13   \n1511998        1          1159.954083                 131          13   \n1511999        1          1170.634154                 132          13   \n\n           energy  cumulative_energy  \n0        0.389667           0.389667  \n1        0.406518           0.796185  \n2        0.296152           1.092337  \n3        0.186119           1.278456  \n4        0.433208           1.711664  \n...           ...                ...  \n1511995  0.271509          30.526758  \n1511996  0.441152          30.967909  \n1511997  0.267868          31.235777  \n1511998  0.267868          31.503645  \n1511999  0.267868          31.771512  \n\n[1512000 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>timing_model</th>\n      <th>sampling_scheme</th>\n      <th>rtt</th>\n      <th>step</th>\n      <th>previous_ttf</th>\n      <th>execution_time</th>\n      <th>step_duration</th>\n      <th>ttf</th>\n      <th>wait_time</th>\n      <th>samples</th>\n      <th>cumulative_duration</th>\n      <th>cumulative_samples</th>\n      <th>repetition</th>\n      <th>energy</th>\n      <th>cumulative_energy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>empirical-high</td>\n      <td>adaptive-constant-Q2-5.2s</td>\n      <td>2.777778</td>\n      <td>1</td>\n      <td>2.777778</td>\n      <td>7.071596</td>\n      <td>11.111111</td>\n      <td>4.039515</td>\n      <td>1.261737</td>\n      <td>3</td>\n      <td>11.111111</td>\n      <td>3</td>\n      <td>12</td>\n      <td>0.389667</td>\n      <td>0.389667</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>empirical-high</td>\n      <td>adaptive-constant-Q2-5.2s</td>\n      <td>2.777778</td>\n      <td>2</td>\n      <td>4.039515</td>\n      <td>8.879713</td>\n      <td>12.234523</td>\n      <td>3.354810</td>\n      <td>0.577032</td>\n      <td>3</td>\n      <td>23.345634</td>\n      <td>6</td>\n      <td>12</td>\n      <td>0.406518</td>\n      <td>0.796185</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>empirical-high</td>\n      <td>adaptive-constant-Q2-5.2s</td>\n      <td>2.777778</td>\n      <td>3</td>\n      <td>3.354810</td>\n      <td>4.495618</td>\n      <td>9.832383</td>\n      <td>5.336765</td>\n      <td>2.558987</td>\n      <td>2</td>\n      <td>33.178017</td>\n      <td>8</td>\n      <td>12</td>\n      <td>0.296152</td>\n      <td>1.092337</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>empirical-high</td>\n      <td>adaptive-constant-Q2-5.2s</td>\n      <td>2.777778</td>\n      <td>4</td>\n      <td>5.336765</td>\n      <td>0.533615</td>\n      <td>7.452374</td>\n      <td>6.918759</td>\n      <td>4.140981</td>\n      <td>1</td>\n      <td>40.630391</td>\n      <td>9</td>\n      <td>12</td>\n      <td>0.186119</td>\n      <td>1.278456</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>empirical-high</td>\n      <td>adaptive-constant-Q2-5.2s</td>\n      <td>2.777778</td>\n      <td>5</td>\n      <td>6.918759</td>\n      <td>8.872578</td>\n      <td>14.013848</td>\n      <td>5.141270</td>\n      <td>2.363493</td>\n      <td>3</td>\n      <td>54.644239</td>\n      <td>12</td>\n      <td>12</td>\n      <td>0.433208</td>\n      <td>1.711664</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1511995</th>\n      <td>theoretical-low</td>\n      <td>adaptive-empirical-low</td>\n      <td>3.888889</td>\n      <td>96</td>\n      <td>6.888578</td>\n      <td>5.993087</td>\n      <td>10.922816</td>\n      <td>4.929729</td>\n      <td>1.040840</td>\n      <td>1</td>\n      <td>1123.539389</td>\n      <td>127</td>\n      <td>13</td>\n      <td>0.271509</td>\n      <td>30.526758</td>\n    </tr>\n    <tr>\n      <th>1511996</th>\n      <td>theoretical-low</td>\n      <td>adaptive-empirical-low</td>\n      <td>3.888889</td>\n      <td>97</td>\n      <td>4.929729</td>\n      <td>7.726390</td>\n      <td>15.054552</td>\n      <td>7.328162</td>\n      <td>3.439273</td>\n      <td>2</td>\n      <td>1138.593941</td>\n      <td>129</td>\n      <td>13</td>\n      <td>0.441152</td>\n      <td>30.967909</td>\n    </tr>\n    <tr>\n      <th>1511997</th>\n      <td>theoretical-low</td>\n      <td>adaptive-empirical-low</td>\n      <td>3.888889</td>\n      <td>98</td>\n      <td>7.328162</td>\n      <td>4.544998</td>\n      <td>10.680071</td>\n      <td>6.135073</td>\n      <td>2.246184</td>\n      <td>1</td>\n      <td>1149.274012</td>\n      <td>130</td>\n      <td>13</td>\n      <td>0.267868</td>\n      <td>31.235777</td>\n    </tr>\n    <tr>\n      <th>1511998</th>\n      <td>theoretical-low</td>\n      <td>adaptive-empirical-low</td>\n      <td>3.888889</td>\n      <td>99</td>\n      <td>6.135073</td>\n      <td>6.428863</td>\n      <td>10.680071</td>\n      <td>4.251207</td>\n      <td>0.362319</td>\n      <td>1</td>\n      <td>1159.954083</td>\n      <td>131</td>\n      <td>13</td>\n      <td>0.267868</td>\n      <td>31.503645</td>\n    </tr>\n    <tr>\n      <th>1511999</th>\n      <td>theoretical-low</td>\n      <td>adaptive-empirical-low</td>\n      <td>3.888889</td>\n      <td>100</td>\n      <td>4.251207</td>\n      <td>6.287216</td>\n      <td>10.680071</td>\n      <td>4.392855</td>\n      <td>0.503966</td>\n      <td>1</td>\n      <td>1170.634154</td>\n      <td>132</td>\n      <td>13</td>\n      <td>0.267868</td>\n      <td>31.771512</td>\n    </tr>\n  </tbody>\n</table>\n<p>1512000 rows × 15 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "from tqdm.notebook import tqdm\n",
    "import multiprocess as mp\n",
    "import shutil\n",
    "\n",
    "result_path = \"./sampling_scaling_rtt.gzip\"\n",
    "combs = set(itertools.product(timing_models.keys(), sampling_schemes.keys(), rtts, range(1, runs_per_model + 1)))\n",
    "\n",
    "# only calculate missing results\n",
    "results = deque()\n",
    "try:\n",
    "    old_results = pd.read_parquet(result_path)\n",
    "    existing_combinations = set(old_results[[\"timing_model\", \"sampling_scheme\", \"rtt\", \"repetition\"]].itertuples(index=False))\n",
    "    shutil.rmtree(result_path)\n",
    "    results.append(old_results)\n",
    "except FileNotFoundError:\n",
    "    existing_combinations = set()\n",
    "\n",
    "combs.difference_update(existing_combinations)\n",
    "if len(combs) == 0:\n",
    "    print(\"No missing combinations.\")\n",
    "else:\n",
    "    with tqdm(total=len(combs), bar_format=\"{l_bar}{bar}{n_fmt}/{total_fmt} [Time: {elapsed}]\") as bar, mp.Pool(os.cpu_count() - 2) as pool:\n",
    "        bar.set_description(\"Running timing model/sampling scheme combinations...\")\n",
    "\n",
    "        def make_callback(cmb: Tuple[str, str, float]) -> Callable[[...], None]:\n",
    "            def _cb(*args, **kwargs) -> None:\n",
    "                bar.update()\n",
    "                bar.set_description(f\"Running timing model/sampling scheme combinations...\")\n",
    "\n",
    "            return _cb\n",
    "\n",
    "        procs = [\n",
    "            pool.apply_async(run_combination, args=c, callback=make_callback(c)) for c in combs\n",
    "        ]\n",
    "\n",
    "        for p in procs:\n",
    "            results.append(p.get())\n",
    "\n",
    "results = pd.concat(results, ignore_index=True)\n",
    "\n",
    "results[\"timing_model\"] = results[\"timing_model\"].astype(\n",
    "    pd.CategoricalDtype([\"fitted-naive\", \"empirical-low\", \"empirical-high\", \"theoretical-low\", \"theoretical-high\"], ordered=True)\n",
    ")\n",
    "results[\"sampling_scheme\"] = results[\"sampling_scheme\"].astype(\n",
    "    pd.CategoricalDtype(sampling_schemes.keys(), ordered=False)\n",
    ")\n",
    "results.to_parquet(result_path, partition_cols=[\"timing_model\", \"sampling_scheme\"], compression=\"gzip\")\n",
    "results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
